{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:17.495137Z",
     "start_time": "2020-08-12T06:00:17.491151Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "\n",
    "spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python. It's designed specifically for production use and helps you build applications that process and \"understand\" large volumes\n",
    "of text.\n",
    "\n",
    "[Documentation](https://spacy.io)\n",
    "\n",
    "Reference: [DataCamp](https://www.datacamp.com/community/blog/spacy-cheatsheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T15:16:01.783967Z",
     "start_time": "2020-08-09T15:16:01.774020Z"
    }
   },
   "source": [
    "**Download statistical models**\n",
    "\n",
    "Predict part-of-speech tags, dependency labels, named entities and more. See here for available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:17.724624Z",
     "start_time": "2020-08-12T06:00:17.502121Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T15:16:01.783967Z",
     "start_time": "2020-08-09T15:16:01.774020Z"
    }
   },
   "source": [
    "**Check that your installed models are up to date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:17.839997Z",
     "start_time": "2020-08-12T06:00:17.727617Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! python -m spacy validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T15:16:01.783967Z",
     "start_time": "2020-08-09T15:16:01.774020Z"
    }
   },
   "source": [
    "**Loading statistical models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:20.629170Z",
     "start_time": "2020-08-12T06:00:17.843988Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing text**\n",
    "\n",
    "Processing text with the nlp object returns a Doc object that holds all information about the tokens, their linguistic features and their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:20.657094Z",
     "start_time": "2020-08-12T06:00:20.632161Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"This is a text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing token attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:20.753869Z",
     "start_time": "2020-08-12T06:00:20.660086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'a', 'text']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing spans**\n",
    "\n",
    "Span indices are exclusive. So `doc[2:4]` is a span starting at token 2, up to – but not including! – token 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:20.857828Z",
     "start_time": "2020-08-12T06:00:20.756833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a text'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = doc[2:4]\n",
    "span.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a span manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:21.002691Z",
     "start_time": "2020-08-12T06:00:20.860793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "doc = nlp(\"I live in New York\")\n",
    "\n",
    "# Span for \"New York\" with label GPE (geopolitical)\n",
    "span = Span(doc, 3, 5, label=\"GPE\")\n",
    "span.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part-of-speech tags (predicted by statistical model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:21.128555Z",
     "start_time": "2020-08-12T06:00:21.008643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DET', 'AUX', 'DET', 'NOUN', 'PUNCT']\n",
      "['DT', 'VBZ', 'DT', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"This is a text.\")\n",
    "\n",
    "# Coarse-grained part-of-speech tags\n",
    "print([token.pos_ for token in doc])\n",
    "\n",
    "# Fine-grained part-of-speech tags\n",
    "print([token.tag_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syntactic dependencies (predicted by statistical model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:21.236702Z",
     "start_time": "2020-08-12T06:00:21.132542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nsubj', 'ROOT', 'det', 'attr', 'punct']\n",
      "['is', 'is', 'text', 'is', 'is']\n"
     ]
    }
   ],
   "source": [
    "# Dependency labels\n",
    "print([token.dep_ for token in doc])\n",
    "\n",
    "# Syntactic head token (governor)\n",
    "print([token.head.text for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Named Entities (predicted by statistical model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:21.335961Z",
     "start_time": "2020-08-12T06:00:21.239698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Larry Page', 'PERSON'), ('Google', 'ORG')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Larry Page founded Google\")\n",
    "# Text and label of named entity span\n",
    "[(ent.text, ent.label_) for ent in doc.ents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentences (usually needs the dependency parser)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:21.487599Z",
     "start_time": "2020-08-12T06:00:21.338952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This a sentence.', 'This is another one.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"This a sentence. This is another one.\")\n",
    "# doc.sents is a generator that yields sentence spans\n",
    "[sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base noun phrases (needs the tagger and parser)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:21.618064Z",
     "start_time": "2020-08-12T06:00:21.492587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'a red car']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"I have a red car\")\n",
    "# doc.noun_chunks is a generator that yields spans\n",
    "[chunk.text for chunk in doc.noun_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label explanations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:21.759777Z",
     "start_time": "2020-08-12T06:00:21.622055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverb\n",
      "Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain(\"RB\"))\n",
    "print(spacy.explain(\"GPE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:22.007966Z",
     "start_time": "2020-08-12T06:00:21.762769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"44da663f6ce5478996f7e2e4bbab375b-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sentence</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-44da663f6ce5478996f7e2e4bbab375b-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-44da663f6ce5478996f7e2e4bbab375b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-44da663f6ce5478996f7e2e4bbab375b-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-44da663f6ce5478996f7e2e4bbab375b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-44da663f6ce5478996f7e2e4bbab375b-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-44da663f6ce5478996f7e2e4bbab375b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(\"This is a sentence\")\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:22.137597Z",
     "start_time": "2020-08-12T06:00:22.010959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Larry Page\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " founded \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Larry Page founded Google\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word vectors and similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:22.270825Z",
     "start_time": "2020-08-12T06:00:22.140589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8868963431185917\n",
      "0.71163386\n",
      "0.004555256\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"I like cats\")\n",
    "doc2 = nlp(\"I like dogs\")\n",
    "\n",
    "# Compare 2 documents\n",
    "print(doc1.similarity(doc2))\n",
    "# Compare 2 tokens\n",
    "print(doc1[2].similarity(doc2[2]))\n",
    "# Compare tokens and spans\n",
    "print(doc1[0].similarity(doc2[1:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing word vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:22.396557Z",
     "start_time": "2020-08-12T06:00:22.273817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.56020373  0.5598117  -1.7227595  -1.4512374  -1.8633732   1.5181652\n",
      "  2.4497442   2.71671     0.7253275  -0.91191405 -2.365035    1.452349\n",
      "  0.99665594 -0.07202923  0.45251393 -0.627396    0.09271556 -0.923568\n",
      "  1.043541   -2.3212037   2.518638    1.0047516  -1.465948    0.16524512\n",
      "  2.3367646   1.0068069  -0.40840077 -1.7979589  -0.01955447 -3.6745605\n",
      " -0.33341095 -1.1460736   0.02087694 -1.0230592  -1.0785705  -0.4837411\n",
      "  3.5818644  -1.6769918  -0.6168177  -0.44305182  1.1309762  -3.375774\n",
      " -0.7314371   3.8165627  -1.2384409  -1.840332    1.9778384  -0.99668455\n",
      " -0.91630244  0.9320802   2.6079159   2.8978107   2.014973   -0.4275763\n",
      " -2.230522    1.5558622  -3.321266    1.4540917  -1.2626281   1.5063637\n",
      " -1.4935691   1.3518717   0.72768307 -2.4933002   2.5934777  -2.8751411\n",
      "  0.70920813 -4.5025535  -1.4368149  -0.4430135  -1.9885433  -2.3653316\n",
      "  0.662556    2.171824    0.14537    -0.92470443  1.3664596   0.4993388\n",
      "  3.4350014  -0.93349695  3.529655    1.2558105  -1.772904    0.47708046\n",
      " -0.2206158  -1.6574367   2.2828362   0.5933906  -1.4959803   0.05929524\n",
      "  1.7404664  -1.8314095   1.531365   -0.7086036  -0.61264044  2.057648  ]\n",
      "17.322075\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I like cats\")\n",
    "\n",
    "print(doc[2].vector)\n",
    "print(doc[2].vector_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline components**\n",
    "\n",
    "Functions that take a Doc object, modify it and return it.\n",
    "\n",
    "![spacy](../meta/spacy.png)\n",
    "\n",
    "Name | Description | Creates\n",
    ":---|:---|:---\n",
    "tagger | Part-of-speech tagger  |Token.tag\n",
    "parser | Dependency parser | Token.dep , Token.head , Doc.sents , Doc.noun_chunks\n",
    "ner | Named entity recognizer | Doc.ents , Token.ent_iob , Token.ent_type\n",
    "textcat | Text classier | Doc.cats\n",
    "\n",
    "* Pipeline is defined in model's meta.json in order\n",
    "* Built-in components need binary data to make predictions\n",
    "\n",
    "**Pipeline information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:22.536476Z",
     "start_time": "2020-08-12T06:00:22.401543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner']\n",
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x000001AD0C73A088>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x000001AD0C681108>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x000001AD0C6811C8>)]\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)\n",
    "\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:22.645367Z",
     "start_time": "2020-08-12T06:00:22.539135Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function that modifies the doc and returns it\n",
    "def custom_component(doc):\n",
    "    print(\"Do something to the doc here!\")\n",
    "    return doc\n",
    "\n",
    "# Add the component first in the pipeline\n",
    "# nlp.add_pipe(custom_component, first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components can be added first, last (default), or before or after an existing component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rule-based matching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:22.791241Z",
     "start_time": "2020-08-12T06:00:22.648359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Each dict represents one token and its attributes\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add with ID, optional callback and pattern(s)\n",
    "pattern = [{\"LOWER\": \"new\"}, {\"LOWER\": \"york\"}]\n",
    "matcher.add('CITIES', None, pattern)\n",
    "\n",
    "# Match by calling the matcher on a Doc object\n",
    "doc = nlp(\"I live in New York\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Matches are (match_id, start, end) tuples\n",
    "for match_id, start, end in matches:\n",
    "     # Get the matched span by slicing the Doc\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:22.922228Z",
     "start_time": "2020-08-12T06:00:22.795229Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"love cats\", \"loving cats\", \"loved cats\"\n",
    "pattern1 = [{\"LEMMA\": \"love\"}, {\"LOWER\": \"cats\"}]\n",
    "# \"10 people\", \"twenty people\"\n",
    "pattern2 = [{\"LIKE_NUM\": True}, {\"TEXT\": \"people\"}]\n",
    "# \"book\", \"a cat\", \"the sea\" (noun + optional article)\n",
    "pattern3 = [{\"POS\": \"DET\", \"OP\": \"?\"}, {\"POS\": \"NOUN\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using operators and quantifiers**\n",
    "\n",
    "Operator | Description\n",
    ":---:|:---\n",
    "`{'OP': '!'}` | Negation: match 0 times\n",
    "`{'OP': '?'}` | Optional: match 0 or 1 times\n",
    "`{'OP': '+'}` | Match 1 or more times\n",
    "`{'OP': '*'}` | Match 0 or more times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shared vocab and string store**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab : stores data shared across multiple documents\n",
    "* To save memory, spaCy encodes all strings to hash values\n",
    "* Strings are only stored once in the StringStore via `nlp.vocab.strings`\n",
    "* String store: lookup table in both directions\n",
    "* Hashes can't be reversed – that's why we need to provide the shared vocab\n",
    "* The doc also exposes the vocab and strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:23.043892Z",
     "start_time": "2020-08-12T06:00:22.925221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash value: 3197928453018144401\n",
      "string value: coffee\n",
      "hash value: 3197928453018144401\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I love coffee\")\n",
    "print('hash value:', nlp.vocab.strings['coffee'])\n",
    "print('string value:', nlp.vocab.strings[3197928453018144401])\n",
    "\n",
    "print('hash value:', doc.vocab.strings['coffee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lexemes: entries in the vocabulary**\n",
    "    \n",
    "A Lexeme object is an entry in the vocabulary\n",
    "* Contains the context-independent information about a word\n",
    "* Word text: lexeme.text and lexeme.orth (the hash)\n",
    "* Lexical attributes like lexeme.is_alpha\n",
    "* Not context-dependent part-of-speech tags, dependencies or entity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:23.178176Z",
     "start_time": "2020-08-12T06:00:23.052868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee 3197928453018144401 True\n"
     ]
    }
   ],
   "source": [
    "lexeme = nlp.vocab['coffee']\n",
    "print(lexeme.text, lexeme.orth, lexeme.is_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T16:03:51.311602Z",
     "start_time": "2020-08-09T16:03:51.302625Z"
    }
   },
   "source": [
    "**Vocab, hashes and lexemes**\n",
    "\n",
    "![](../meta/spacy-lexeme.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing large volumes of text**\n",
    "* Use nlp.pipe method\n",
    "* Processes texts as a stream, yields Doc objects\n",
    "* Much faster than calling nlp on each text\n",
    "\n",
    "BAD:\n",
    "```\n",
    "docs = [nlp(text) for text in LOTS_OF_TEXTS]\n",
    "```\n",
    "GOOD:\n",
    "```\n",
    "docs = list(nlp.pipe(LOTS_OF_TEXTS))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passing in context**\n",
    "\n",
    "* Setting as_tuples=True on nlp.pipe lets you pass in (text, context) tuples\n",
    "* Yields (doc, context) tuples\n",
    "* Useful for associating metadata with the doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:23.299339Z",
     "start_time": "2020-08-12T06:00:23.183158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a text 15\n",
      "And another text 16\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ('This is a text', {'id': 1, 'page_number': 15}),\n",
    "    ('And another text', {'id': 2, 'page_number': 16}),\n",
    "]\n",
    "for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "    print(doc.text, context['page_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:23.464851Z",
     "start_time": "2020-08-12T06:00:23.304299Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "Doc.set_extension('id', default=None)\n",
    "Doc.set_extension('page_number', default=None)\n",
    "data = [\n",
    "    ('This is a text', {'id': 1, 'page_number': 15}),\n",
    "    ('And another text', {'id': 2, 'page_number': 16}),\n",
    "]\n",
    "for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "    doc._.id = context['id']\n",
    "    doc._.page_number = context['page_number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using only the tokenizer**\n",
    "\n",
    "* Use nlp.make_doc to turn a text in to a Doc object\n",
    "* Use nlp.disable_pipes to temporarily disable one or more pipes\n",
    "* restores them after the with block\n",
    "* only runs the remaining components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T06:00:23.602249Z",
     "start_time": "2020-08-12T06:00:23.467757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Larry Page, Google)\n"
     ]
    }
   ],
   "source": [
    "text = \"Larry Page founded Google\"\n",
    "with nlp.disable_pipes('tagger', 'parser'):\n",
    "    doc = nlp(text)\n",
    "    print(doc.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and updating models**\n",
    "\n",
    "**Why updating the model?**\n",
    "\n",
    "* Better results on your specic domain\n",
    "* Learn classication schemes specically for your problem\n",
    "* Essential for text classication\n",
    "* Very useful for named entity recognition\n",
    "* Less critical for part-of-speech tagging and dependency parsing\n",
    "\n",
    "**How training works**\n",
    "\n",
    "1. Initialize the model weights randomly with nlp.begin_training\n",
    "2. Predict a few examples with the current weights by calling nlp.update\n",
    "3. Compare prediction with true labels\n",
    "4. Calculate how to change weights to improve predictions\n",
    "5. Update weights slightly\n",
    "6. Go back to 2\n",
    "\n",
    "**Training the entity recognizer**\n",
    "\n",
    "* The entity recognizer tags words and phrases in context\n",
    "* Each token can only be part of one entity\n",
    "* Examples need to come with context\n",
    "```\n",
    "(\"iPhone X is coming\", {'entities': [(0, 8, 'GADGET')]})\n",
    "```\n",
    "* Texts with no entities are also important\n",
    "```\n",
    "(\"I need a new phone! Any tips?\" , {'entities': []})\n",
    "```\n",
    "* Goal:teach the model to generalize\n",
    "\n",
    "* Update an existing model: a few hundred to a few thousand examples\n",
    "* Train a new category: a few thousand to a million examples\n",
    "* spaCy's English models: 2 million words\n",
    "* Usually created manually by human annotators\n",
    "* Can be semi-automated – for example, using spaCy's Matcher !\n",
    "\n",
    "\n",
    "**The steps of a training loop**\n",
    "\n",
    "1. Loop for a number oftimes.\n",
    "2. Shufe the training data.\n",
    "3. Divide the data into batches.\n",
    "4. Update the model for each batch.\n",
    "5. Save the updated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TRAINING_DATA = [\n",
    "(\"How to preorder the iPhone X\", {'entities': [(20, 28, 'GADGET')]})\n",
    "# And many more examples...\n",
    "]\n",
    "\n",
    "for i in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    # Create batches and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA):\n",
    "        # Split the batch in texts and annotations\n",
    "        texts = [text for text, annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations)\n",
    "# Save the model\n",
    "nlp.to_disk(path_to_model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up a new pipeline from scratch**\n",
    "\n",
    "```\n",
    "# Start with blank English model\n",
    "nlp = spacy.blank('en')\n",
    "# Create blank entity recognizer and add it to the pipeline\n",
    "ner = nlp.create_pipe('ner')\n",
    "nlp.add_pipe(ner)\n",
    "# Add a new label\n",
    "ner.add_label('GADGET')\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "# Train for 10 iterations\n",
    "for itn in range(10):\n",
    "    random.shuffle(examples)\n",
    "    # Divide examples into batches\n",
    "    for batch in spacy.util.minibatch(examples, size=2):\n",
    "        texts = [text for text, annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
