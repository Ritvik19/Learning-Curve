{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNNImputer\n",
    "\n",
    "Reference: [KNNImputer: A robust way to impute missing values (using Scikit-Learn)](https://www.analyticsvidhya.com/blog/2020/07/knnimputer-a-robust-way-to-impute-missing-values-using-scikit-learn/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "KNNImputer by scikit-learn is a widely used method to impute missing values. It is widely being observed as a replacement for traditional imputation techniques.\n",
    "\n",
    "In today’s world, data is being collected from a number of sources and is used for analyzing, generating insights, validating theories, and whatnot. This data collected from different resources may often have some information missing. This may be due to a problem in the data collection or extraction process that could be a human error.\n",
    "\n",
    "Dealing with these missing values, thus becomes an important step in data preprocessing. The choice of method of imputation is crucial since it can significantly impact one’s work.\n",
    "\n",
    "Most statistical and machine learning algorithms work on complete observations of a dataset. As a result, it becomes essential to deal with missing information. A handful of literature in statistics deals with the source of missing values and ways to overcome the issue. The best way is to impute these missing observations with an estimated value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem of Degrees of Freedom\n",
    "Missing values in a dataset can be a hornet’s nest for any data scientist. Variables with missing values can be a non-trivial problem as there is no easy way out to deal with them.\n",
    "\n",
    "Generally, if the proportion of missing observations in data is small relative to the total number of observations, we can simply remove those observations. However, this is not the most often case. Deleting the rows containing missing values may lead to parting away with useful information or patterns.\n",
    "\n",
    "> In statistical terms, this leads to reduced degrees of freedom as the number of independent pieces of information goes down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Patterns\n",
    "The absence of values is a cause of concern for real-life datasets. When collecting observations about a variable, missing values can occur due to reasons as diverse as –\n",
    "\n",
    "* an error in machinery/equipment\n",
    "* error on part of the researcher\n",
    "* unavailable respondents\n",
    "* accidental deletion of observations\n",
    "* forgetfulness on part of the respondents\n",
    "* error in accounting, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of missing values can generally be classified as:\n",
    "\n",
    "## Missing Completely at Random (MCAR)\n",
    "This happens when the missing values have no hidden dependency on any other variable or any characteristic of observations. If a doctor forgets to record the age of every tenth patient entering an ICU, the presence of missing value would not depend on the characteristic of the patients.\n",
    "\n",
    "## Missing at Random (MAR)\n",
    "In this case, the probability of missing value depends on the characteristics of observable data. In survey data, high income respondents are less likely to inform the researcher about number of properties owned. The missing value for the variable number of properties owned will depend on the income variable.\n",
    "\n",
    "## Missing Not at Random (MNAR)\n",
    "This happens when the missing values depend on both characteristics of the data and also on missing values. In this case,  determining the mechanism of generation of missing value is difficult. For example, missing values for a variable like blood pressure may partially depend on the values of blood pressure as patients who have low blood pressure are less likely to get their blood pressure checked at frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A shared sense of identity (Essence of kNN algorithm)\n",
    "Univariate methods used for missing value imputation are simplistic ways of estimating the value and may not provide an accurate picture always. For example, let us say we have variables related to the density of cars on road and levels of pollutants in the air and there are few observations that are missing for the level of pollutants, imputing the level of pollutants by mean/median level of pollutants may not necessarily be an appropriate strategy.\n",
    "\n",
    "In such scenarios, algorithms like k-Nearest Neighbors (kNN) can help to impute the values of missing data. Sociologists and community researchers suggest that human beings live in a community because neighbors generate a feeling of security and safety, attachment to community, and relationships that bring out a community identity through participation in various activities.\n",
    "\n",
    "A similar imputation methodology that works on data is k-Nearest Neighbours (kNN) that identifies the neighboring points through a measure of distance and the missing values can be estimated using completed values of neighboring observations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance calculation in the presence of missing values\n",
    "\n",
    "In the presence of missing coordinates, the Euclidean distance is calculated by ignoring the missing values and scaling up the weight of the non-missing coordinates.\n",
    "\n",
    "![](https://lh3.googleusercontent.com/XoAmDPvK6VdXeR1Tvbre0GGPrVhjt0lKfsctH_U_DO4nTLMEQzFe0Cavzs50kqHdvBr483UA5HxJEOptHxBYtyRY5FTON28Yj4Q70oCeh-4Opk5KXojX5BwqUAEJRn2xiHtLoRdU)\n",
    "\n",
    "where,\n",
    "\n",
    "![](https://lh5.googleusercontent.com/Ifp1O-KCM1gG0aQXXJbT3RLtTNC1eICgKhFZ89p25jzvujerKmEcn9nFXWVls16oZ-aWxBu7k4iockd3ohWyFh_jga8589F6Ra8h2lLc959pBClCGdGPoZhx0kbYnOlD4cRKK5fM)\n",
    "\n",
    "For example, the Euclidean distances between two points (3, NA, 5) and (1, 0, 0) is:\n",
    "\n",
    "![](https://lh5.googleusercontent.com/nPFpe1oPKYB1xUwU4GGxCrAEpi3pNBDckj0Jza5cMFGkA-tjMZAWQzEtqK1DJXJt0ZuOFcCoVymyIUzVEyBl_8bWRhFWA9k7x3AHiMgFxjXYaHzkx7qIQR24u3_p8TJkw6IMBj8i)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation Approach with KNNImputer\n",
    "We will use the KNNImputer function from the impute module of the sklearn. KNNImputer helps to impute missing values present in the observations by finding the nearest neighbors with the Euclidean distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T05:24:06.660839Z",
     "start_time": "2020-07-14T05:24:05.476852Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T05:24:06.692689Z",
     "start_time": "2020-07-14T05:24:06.663765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 3., 5.],\n",
       "       [1., 0., 0.],\n",
       "       [3., 3., 3.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[3, np.nan, 5], [1, 0, 0], [3, 3, 3]]\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "X = imputer.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
