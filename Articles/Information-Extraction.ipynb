{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:05.459067Z",
     "start_time": "2020-07-02T16:28:02.913364Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy \n",
    "from spacy.matcher import Matcher \n",
    "\n",
    "import visualise_spacy_tree\n",
    "from IPython.display import Image, display\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:05.992546Z",
     "start_time": "2020-07-02T16:28:05.463058Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Ritvik\\Anaconda3\\envs\\ailab\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Extraction\n",
    "\n",
    "The task of Information Extraction (IE) involves extracting meaningful information from unstructured text data and presenting it in a structured format.\n",
    "\n",
    "* Reference: [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2020/06/nlp-project-information-extraction/) \n",
    "* Supplimentary: [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2019/09/introduction-information-extraction-python-spacy/?utm_source=blog&utm_medium=nlp-project-information-extraction)\n",
    "\n",
    "Information Extraction (IE) is a crucial cog in the field of Natural Language Processing (NLP) and linguistics. It’s widely used for tasks such as Question Answering Systems, Machine Translation, Entity Extraction, Event Extraction, Named Entity Linking, Coreference Resolution, Relation Extraction, etc.\n",
    "\n",
    "In information extraction, there is an important concept of triples.\n",
    "\n",
    "> A triple represents a couple of entities and a relation between them. For example, (Obama, born, Hawaii) is a triple in which ‘Obama’ and ‘Hawaii’ are the related entities, and the relation between them is ‘born’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T17:50:41.261474Z",
     "start_time": "2020-06-29T17:50:41.254492Z"
    }
   },
   "source": [
    "## Different approaches to Information Extraction\n",
    "\n",
    "![ietypes](../meta/IE_types.webp)\n",
    "\n",
    "* In Traditional Information Extraction, the relations to be extracted are pre-defined\n",
    "\n",
    "* In Open Information Extraction, the relations are not pre-defined. The system is free to extract any relations it comes across while going through the text data.\n",
    "\n",
    "### Different Approaches to Traditional Information Extraction\n",
    "\n",
    "* Rule-based Approach: We define a set of rules for the syntax and other grammatical properties of a natural language and then use these rules to extract information from text\n",
    "* Supervised: Let’s say we have a sentence S. It has two entities E1 and E2. Now, the supervised machine learning model has to detect whether there is any relation (R) between E1 and E2. So, in a supervised approach, the task of relation extraction turns into the task of relation detection. The only drawback of this approach is that it needs a lot of labeled data to train a model\n",
    "* Semi-supervised: When we don’t have enough labeled data, we can use a set of seed examples (triples) to formulate high-precision patterns that can be used to extract more relations from the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Extraction using spaCy\n",
    "\n",
    "\n",
    "We all know that sentences are made up of words belonging to different Parts of Speech (POS). There are eight different POS in the English language: noun, pronoun, verb, adjective, adverb, preposition, conjunction, and intersection.\n",
    "\n",
    "The POS determines how a specific word functions in meaning in a given sentence. For example, take the word “right”. In the sentence, “The boy was awarded chocolate for giving the right answer”, “right” is used as an adjective. Whereas, in the sentence, “You have the right to say whatever you want”, “right” is treated as a noun.\n",
    "\n",
    "This goes to show that the POS tag of a word carries a lot of significance when it comes to understanding the meaning of a sentence. And we can leverage it to extract meaningful information from our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:06.029446Z",
     "start_time": "2020-07-02T16:28:05.996533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This -> DET\n",
      "is -> AUX\n",
      "a -> DET\n",
      "sample -> NOUN\n",
      "sentence -> NOUN\n",
      ". -> PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a sample sentence.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,'->',token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we wanted to extract nouns from the sentences, we could take a look at POS tags of the words/tokens in the sentence, using the attribute .pos_, and extract them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:06.147803Z",
     "start_time": "2020-07-02T16:28:06.034433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\n",
      "sentence\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.pos_ == 'NOUN':\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was that easy to extract words based on their POS tags. But sometimes extracting information purely based on the POS tags is not enough. Have a look at the sentence below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:06.314977Z",
     "start_time": "2020-07-02T16:28:06.150791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The -> DET\n",
      "children -> NOUN\n",
      "love -> VERB\n",
      "cream -> NOUN\n",
      "biscuits -> NOUN\n"
     ]
    }
   ],
   "source": [
    "text = \"The children love cream biscuits\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,'->',token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I wanted to extract the subject and the object from a sentence, I can’t do that based on their POS tags. For that, I need to look at how these words are related to each other. These are called Dependencies.\n",
    "\n",
    "We can make use of spaCy’s displacy visualizer that displays the word dependencies in a graphical manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:06.444546Z",
     "start_time": "2020-07-02T16:28:06.317935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4eefacbaecdb4379961ce52243b8776f-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">children</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">love</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">cream</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">biscuits</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4eefacbaecdb4379961ce52243b8776f-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4eefacbaecdb4379961ce52243b8776f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4eefacbaecdb4379961ce52243b8776f-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4eefacbaecdb4379961ce52243b8776f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4eefacbaecdb4379961ce52243b8776f-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4eefacbaecdb4379961ce52243b8776f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4eefacbaecdb4379961ce52243b8776f-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4eefacbaecdb4379961ce52243b8776f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"The children love cream biscuits\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "displacy.render(doc, style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This directed graph is known as a dependency graph. It represents the relations between different words of a sentence.\n",
    "\n",
    "Each word is a node in the Dependency graph. The relationship between words is denoted by the edges. For example, “The” is a determiner here, “children” is the subject of the sentence, “biscuits” is the object of the sentence, and “cream” is a compound word that gives us more information about the object.\n",
    "\n",
    "The arrows carry a lot of significance here:\n",
    "\n",
    "* The arrowhead points to the words that are dependent on the word pointed by the origin of the arrow\n",
    "* The former is referred to as the child node of the latter. For example, “children” is the child node of “love”\n",
    "* The word which has no incoming arrow is called the root node of the sentence\n",
    "\n",
    "Like we have an attribute for POS in SpaCy tokens, we similarly have an attribute for extracting the dependency of a token denoted by dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:06.576022Z",
     "start_time": "2020-07-02T16:28:06.447537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects:\n",
      "children\n",
      "\n",
      "Objects:\n",
      "biscuits\n"
     ]
    }
   ],
   "source": [
    "print('Subjects:')        \n",
    "print(*[token.text for token in doc if token.dep_ == 'nsubj'])\n",
    "print()\n",
    "print('Objects:')        \n",
    "print(*[token.text for token in doc if token.dep_ == 'dobj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using POS tags and Dependency tags, we can look for relationships between different entities in a sentence. For example, in the sentence “The cat perches on the window sill“, we have the subject, “cat”, the object “window sill”, related by the preposition “on”. We can look for such relationships and much more to extract meaningful information from our text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  United Nations General Debate Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:06.729069Z",
     "start_time": "2020-07-02T16:28:06.580982Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../meta/UNDP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Extraction using SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule on Noun-Verb-Noun Phrases\n",
    "\n",
    "When you look at a sentence, it generally contains a subject (noun), action (verb), and an object (noun). The rest of the words are just there to give us additional information about the entities. Therefore, we can leverage this basic structure to extract the main bits of information from the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:06.836663Z",
     "start_time": "2020-07-02T16:28:06.732977Z"
    }
   },
   "outputs": [],
   "source": [
    "def rule1(text):\n",
    "    doc = nlp(text)\n",
    "    sent = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.pos_=='VERB'):\n",
    "            phrase = ''\n",
    "            for sub_tok in token.lefts:\n",
    "                if (sub_tok.dep_ in ['nsubj','nsubjpass']) and (sub_tok.pos_ in ['NOUN','PROPN','PRON']):\n",
    "                    phrase += sub_tok.text\n",
    "                    phrase += ' '+token.lemma_ \n",
    "                    for sub_tok in token.rights:\n",
    "                        if (sub_tok.dep_ in ['dobj']) and (sub_tok.pos_ in ['NOUN','PROPN']):       \n",
    "                            phrase += ' '+sub_tok.text\n",
    "                            sent.append(phrase)\n",
    "            \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:07.133475Z",
     "start_time": "2020-07-02T16:28:06.839659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Industrialized countries with planned economies, which do not formally belong to the international monetary system but participate in the global activities of commerce and technological exchange, also face problems of production and renovation -> ['countries face problems']\n",
      "\n",
      "\n",
      "\n",
      " The entry of these two countries into the United Nations has taken this Organization one step closer to its goal of universality -> ['entry take Organization']\n",
      "\n",
      "\n",
      "\n",
      " The two United Nations Development Decades, one of the 1960s and the other of the 1970s, and a series of protracted negotiations, have proved sterile exercises, belying the hopes that had been raised that inequity between nations need not be an inexorable law and that, for reasons as much economic as ethical, the rich should assist the poor -> ['Decades prove exercises']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in df['Sent'].sample(10, random_state=19).values:\n",
    "    rule = rule1(sent)\n",
    "    if rule != []:\n",
    "        print(sent, '->', rule)\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule on Adjective Noun Structure\n",
    "\n",
    "In the previous rule that, the information did not feel complete. This is because many nouns have an adjective or a word with a compound dependency that augments the meaning of a noun. Extracting these along with the noun will give us better information about the subject and the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:07.146438Z",
     "start_time": "2020-07-02T16:28:07.136464Z"
    }
   },
   "outputs": [],
   "source": [
    "def rule2(text):\n",
    "    doc = nlp(text)\n",
    "    sent = []\n",
    "    \n",
    "    for token in doc:\n",
    "        phrase = ''\n",
    "        if (token.pos_ == 'NOUN') and (token.dep_ in ['dobj','pobj','nsubj','nsubjpass']):\n",
    "            for subtoken in token.children:\n",
    "                if (subtoken.pos_ == 'ADJ') or (subtoken.dep_ == 'compound'):\n",
    "                    phrase += subtoken.text + ' '\n",
    "            if len(phrase)!=0:\n",
    "                phrase += token.text \n",
    "        if  len(phrase)!=0:\n",
    "            sent.append(phrase)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:07.410034Z",
     "start_time": "2020-07-02T16:28:07.149432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There is renewed awareness of the continued relevance of his message of non violence and tolerance -> ['non violence']\n",
      "\n",
      "\n",
      "\n",
      " Industrialized countries with planned economies, which do not formally belong to the international monetary system but participate in the global activities of commerce and technological exchange, also face problems of production and renovation -> ['Industrialized countries', 'international monetary system', 'global activities']\n",
      "\n",
      "\n",
      "\n",
      " There can be no durable peace in West Asia without a just and comprehensive settlement, based on the realization by the Palestinian people of their inalienable right to self determination and the recognition of the rights of all States in the region, including Palestine and Israel, to live in peace and security within internationally recognized borders -> ['just settlement', 'Palestinian people', 'inalienable right', 'self determination']\n",
      "\n",
      "\n",
      "\n",
      " The bulk of the global military expenditure of $1 trillion a year is accounted for by a handful of industrialized countries -> ['global military expenditure']\n",
      "\n",
      "\n",
      "\n",
      " We are now on the threshold of the third United Nations Development Decade, covering the 1980s, and of the special session of the United Nations which will be held next year -> ['special session']\n",
      "\n",
      "\n",
      "\n",
      " The two United Nations Development Decades, one of the 1960s and the other of the 1970s, and a series of protracted negotiations, have proved sterile exercises, belying the hopes that had been raised that inequity between nations need not be an inexorable law and that, for reasons as much economic as ethical, the rich should assist the poor -> ['protracted negotiations', 'sterile exercises', 'economic reasons']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in df['Sent'].sample(10, random_state=19).values:\n",
    "    rule = rule2(sent)\n",
    "    if rule != []:\n",
    "        print(sent, '->', rule)\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:32:45.860085Z",
     "start_time": "2020-06-29T16:32:45.844423Z"
    }
   },
   "source": [
    "## Combining both rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:07.427988Z",
     "start_time": "2020-07-02T16:28:07.413057Z"
    }
   },
   "outputs": [],
   "source": [
    "def rule1_mod(text):\n",
    "    doc = nlp(text)\n",
    "    sent = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.pos_=='VERB'):\n",
    "            phrase = {'verb': [], 'sub':[], 'sub_adj':[], 'obj':[], 'obj_adj':[]}\n",
    "            for sub_tok in token.lefts:\n",
    "                if (sub_tok.dep_ in ['nsubj','nsubjpass']) and (sub_tok.pos_ in ['NOUN','PROPN','PRON']):\n",
    "                    for sub_sub_tok in sub_tok.children:\n",
    "                        if sub_sub_tok.pos_ == 'ADJ':\n",
    "                            phrase['sub_adj'].append(sub_sub_tok.text)\n",
    "                    phrase['sub'].append(sub_tok.text)\n",
    "                    phrase['verb'].append(token.lemma_)\n",
    "                    for sub_tok in token.rights:\n",
    "                        if (sub_tok.dep_ in ['dobj']) and (sub_tok.pos_ in ['NOUN','PROPN']):\n",
    "                            for sub_sub_tok in sub_tok.children:\n",
    "                                if sub_sub_tok.pos_ == 'ADJ':\n",
    "                                    phrase['obj_adj'].append(sub_sub_tok.text)\n",
    "                            phrase['obj'].append(sub_tok.text)\n",
    "                            sent.append(phrase)\n",
    "            \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:07.696166Z",
     "start_time": "2020-07-02T16:28:07.430976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Industrialized countries with planned economies, which do not formally belong to the international monetary system but participate in the global activities of commerce and technological exchange, also face problems of production and renovation -> [{'verb': ['face'], 'sub': ['countries'], 'sub_adj': [], 'obj': ['problems'], 'obj_adj': []}]\n",
      "\n",
      "\n",
      "\n",
      " The entry of these two countries into the United Nations has taken this Organization one step closer to its goal of universality -> [{'verb': ['take'], 'sub': ['entry'], 'sub_adj': [], 'obj': ['Organization'], 'obj_adj': []}]\n",
      "\n",
      "\n",
      "\n",
      " The two United Nations Development Decades, one of the 1960s and the other of the 1970s, and a series of protracted negotiations, have proved sterile exercises, belying the hopes that had been raised that inequity between nations need not be an inexorable law and that, for reasons as much economic as ethical, the rich should assist the poor -> [{'verb': ['prove'], 'sub': ['Decades'], 'sub_adj': [], 'obj': ['exercises'], 'obj_adj': ['sterile']}]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in df['Sent'].sample(10, random_state=19).values:\n",
    "    rule = rule1_mod(sent)\n",
    "    if rule != []:\n",
    "        print(sent, '->', rule)\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule on Prepositions\n",
    "\n",
    "Prepositions tell us where or when something is in a relationship with something else. For example, The people of India believe in the principles of the United Nations. Clearly extracting phrases including prepositions will give us a lot of information from the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:07.707137Z",
     "start_time": "2020-07-02T16:28:07.698159Z"
    }
   },
   "outputs": [],
   "source": [
    "def rule3(text):\n",
    "    doc = nlp(text)\n",
    "    sent = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_=='ADP':\n",
    "            phrase = ''\n",
    "            if token.head.pos_=='NOUN':\n",
    "                phrase += token.head.text\n",
    "                phrase += ' '+token.text\n",
    "                for right_tok in token.rights:\n",
    "                    if (right_tok.pos_ in ['NOUN','PROPN']):\n",
    "                        phrase += ' '+right_tok.text\n",
    "                \n",
    "                if len(phrase)>2:\n",
    "                    sent.append(phrase)\n",
    "                \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:07.956572Z",
     "start_time": "2020-07-02T16:28:07.710129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There is renewed awareness of the continued relevance of his message of non violence and tolerance -> ['awareness of relevance', 'relevance of message', 'message of violence']\n",
      "\n",
      "\n",
      "\n",
      " Industrialized countries with planned economies, which do not formally belong to the international monetary system but participate in the global activities of commerce and technological exchange, also face problems of production and renovation -> ['countries with economies', 'activities of exchange', 'problems of production']\n",
      "\n",
      "\n",
      "\n",
      " The entry of these two countries into the United Nations has taken this Organization one step closer to its goal of universality -> ['entry of countries', 'entry into Nations', 'goal of universality']\n",
      "\n",
      "\n",
      "\n",
      " There can be no durable peace in West Asia without a just and comprehensive settlement, based on the realization by the Palestinian people of their inalienable right to self determination and the recognition of the rights of all States in the region, including Palestine and Israel, to live in peace and security within internationally recognized borders -> ['peace in Asia', 'peace without settlement', 'realization by people', 'people of right determination', 'self to', 'recognition of rights', 'rights of States']\n",
      "\n",
      "\n",
      "\n",
      " The bulk of the global military expenditure of $1 trillion a year is accounted for by a handful of industrialized countries -> ['bulk of expenditure', 'expenditure of', 'handful of countries']\n",
      "\n",
      "\n",
      "\n",
      " He also referred to the resolutions of the Security Council of 1948 and 1949 -> ['resolutions of Council']\n",
      "\n",
      "\n",
      "\n",
      " We are now on the threshold of the third United Nations Development Decade, covering the 1980s, and of the special session of the United Nations which will be held next year -> ['threshold of Decade', 'session of Nations']\n",
      "\n",
      "\n",
      "\n",
      " The two United Nations Development Decades, one of the 1960s and the other of the 1970s, and a series of protracted negotiations, have proved sterile exercises, belying the hopes that had been raised that inequity between nations need not be an inexorable law and that, for reasons as much economic as ethical, the rich should assist the poor -> ['series of negotiations', 'inequity between nations']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in df['Sent'].sample(10, random_state=19).values:\n",
    "    rule = rule3(sent)\n",
    "    if rule != []:\n",
    "        print(sent, '->', rule)\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:07.977515Z",
     "start_time": "2020-07-02T16:28:07.959562Z"
    }
   },
   "outputs": [],
   "source": [
    "def rule3_mod(text):\n",
    "    doc = nlp(text)\n",
    "    sent = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_=='ADP':\n",
    "            phrase = {'noun1': [], 'prep': [], 'noun2': []}\n",
    "            if token.head.pos_=='NOUN':\n",
    "                entity = ''\n",
    "                for sub_tok in token.head.children:\n",
    "                    if (sub_tok.dep_ in ['compound','amod']):\n",
    "                        entity += sub_tok.text+' '             \n",
    "                if len(entity)!=0:\n",
    "                    phrase['noun1'].append(entity)\n",
    "                else:  \n",
    "                    phrase['noun1'].append(token.head.text)\n",
    "                phrase['prep'].append(token.text)\n",
    "\n",
    "                for right_tok in token.rights:\n",
    "                    if (right_tok.pos_ in ['NOUN','PROPN']):\n",
    "                        entity = ''\n",
    "                        for sub_tok in token.head.children:\n",
    "                            if (sub_tok.dep_ in ['compound','amod']):\n",
    "                                entity += sub_tok.text+' '\n",
    "                        if len(entity)!=0:\n",
    "                            phrase['noun2'].append(entity)\n",
    "                        else:\n",
    "                            phrase['noun2'].append(token.head.text)\n",
    "                \n",
    "                sent.append(phrase)\n",
    "                \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T16:28:08.252186Z",
     "start_time": "2020-07-02T16:28:07.980506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There is renewed awareness of the continued relevance of his message of non violence and tolerance -> [{'noun1': ['renewed '], 'prep': ['of'], 'noun2': ['renewed ']}, {'noun1': ['continued '], 'prep': ['of'], 'noun2': ['continued ']}, {'noun1': ['message'], 'prep': ['of'], 'noun2': ['message']}]\n",
      "\n",
      "\n",
      "\n",
      " Industrialized countries with planned economies, which do not formally belong to the international monetary system but participate in the global activities of commerce and technological exchange, also face problems of production and renovation -> [{'noun1': ['Industrialized '], 'prep': ['with'], 'noun2': ['Industrialized ']}, {'noun1': ['global '], 'prep': ['of'], 'noun2': ['global ']}, {'noun1': ['problems'], 'prep': ['of'], 'noun2': ['problems']}]\n",
      "\n",
      "\n",
      "\n",
      " The entry of these two countries into the United Nations has taken this Organization one step closer to its goal of universality -> [{'noun1': ['entry'], 'prep': ['of'], 'noun2': ['entry']}, {'noun1': ['entry'], 'prep': ['into'], 'noun2': ['entry']}, {'noun1': ['goal'], 'prep': ['of'], 'noun2': ['goal']}]\n",
      "\n",
      "\n",
      "\n",
      " There can be no durable peace in West Asia without a just and comprehensive settlement, based on the realization by the Palestinian people of their inalienable right to self determination and the recognition of the rights of all States in the region, including Palestine and Israel, to live in peace and security within internationally recognized borders -> [{'noun1': ['durable '], 'prep': ['in'], 'noun2': ['durable ']}, {'noun1': ['durable '], 'prep': ['without'], 'noun2': ['durable ']}, {'noun1': ['realization'], 'prep': ['by'], 'noun2': ['realization']}, {'noun1': ['Palestinian '], 'prep': ['of'], 'noun2': ['Palestinian ', 'Palestinian ']}, {'noun1': ['self'], 'prep': ['to'], 'noun2': []}, {'noun1': ['recognition'], 'prep': ['of'], 'noun2': ['recognition']}, {'noun1': ['rights'], 'prep': ['of'], 'noun2': ['rights']}]\n",
      "\n",
      "\n",
      "\n",
      " The bulk of the global military expenditure of $1 trillion a year is accounted for by a handful of industrialized countries -> [{'noun1': ['bulk'], 'prep': ['of'], 'noun2': ['bulk']}, {'noun1': ['global military '], 'prep': ['of'], 'noun2': []}, {'noun1': ['handful'], 'prep': ['of'], 'noun2': ['handful']}]\n",
      "\n",
      "\n",
      "\n",
      " He also referred to the resolutions of the Security Council of 1948 and 1949 -> [{'noun1': ['resolutions'], 'prep': ['of'], 'noun2': ['resolutions']}]\n",
      "\n",
      "\n",
      "\n",
      " We are now on the threshold of the third United Nations Development Decade, covering the 1980s, and of the special session of the United Nations which will be held next year -> [{'noun1': ['threshold'], 'prep': ['of'], 'noun2': ['threshold']}, {'noun1': ['special '], 'prep': ['of'], 'noun2': ['special ']}]\n",
      "\n",
      "\n",
      "\n",
      " The two United Nations Development Decades, one of the 1960s and the other of the 1970s, and a series of protracted negotiations, have proved sterile exercises, belying the hopes that had been raised that inequity between nations need not be an inexorable law and that, for reasons as much economic as ethical, the rich should assist the poor -> [{'noun1': ['series'], 'prep': ['of'], 'noun2': ['series']}, {'noun1': ['inequity'], 'prep': ['between'], 'noun2': ['inequity']}]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in df['Sent'].sample(10, random_state=19).values:\n",
    "    rule = rule3_mod(sent)\n",
    "    if rule != []:\n",
    "        print(sent, '->', rule)\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
